[
  {
    "objectID": "permutation_test.html",
    "href": "permutation_test.html",
    "title": "Financial Institution’s effect on GDP",
    "section": "",
    "text": "Context of the problem:\nThe point of this analysis is to explore how access to financial institutions and services such as having a checking account correlates with a nation’s GDP and to explore the relationship between the two. We are exploring GDP per Capita for 120 nations in USD. We are measuring how GDP per Capita is correlates with the percent of the population 15+ and older who have access to a financial institution account. Among the data we also have other variables to measure access to financial institutions such as:\nSaved at a financial institution (% age 15+)\nBorrowed from a formal financial institution (% age 15+)\nAccount, female (% age 15+)\nAccount, male (% age 15+)\nOwns a credit card (% age 15+)\nI split countries into two groups based on the median GDP per Capita:\nHigh GDP group: Countries above the median\nLow GDP group: Countries below the median\nWhy this is interesting to analyze:\nUnderstanding if economic development relates to financial inclusion can be interesting to study to hopefully understand what makes a nation wealthy and may aid in policy and development strategy. If we notice countries with greater access to financial institutions have a larger GDP per Capita than maybe we can identify financial institutions as one of many potential drivers in generating wealth for a country. Understanding this could help address policy going forward in low-income countries. If these countries implement policies that expand access to financial institutions, it could help increase their GDP per Capita and improve a nation’s wealth, which would also improve the standard of living, overall happiness, and quality of life. Though studying this relationship does not mean there is a direct cause, it could be the start of a study in which we could hopefully identify the cause eventually. We are mostly understanding the relationship, but if there is a significant relationship, it is interesting to hypothesize that there may be some causation.\nExploratory Analysis:\n\n# Load and clean GDP dataset, assign GDP groups based on the median GDP per capita\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nGDP_analysis &lt;- read_excel(\"GDP_analysis.xlsx\", sheet = \"Data\", skip = 1)\ncolnames(GDP_analysis) &lt;- c(\n  \"Country\", \n  \"GDP_Per_Capita\", \n  \"Account_15plus\", \n  \"Saved_15plus\", \n  \"Borrowed_Formal_15plus\", \n  \"Account_Female\", \n  \"Account_Male\", \n  \"Owns_Credit_Card\")\n\nDP_analysis &lt;- GDP_analysis |&gt; \n  mutate(across(GDP_Per_Capita:Owns_Credit_Card, as.numeric))\n  \nmedian_gdp &lt;- GDP_analysis |&gt;\n  summarise(median_gdp = median(GDP_Per_Capita, na.rm = TRUE)) |&gt;\n  pull(median_gdp)\n\nGDP_analysis &lt;- GDP_analysis |&gt;  \n  mutate(GDP_Group = ifelse(GDP_Per_Capita &gt;= median_gdp, \"High\", \"Low\"))\n\n\n# Creates a boxplot to compare account ownership (age 15+) between high and low-GDP countries.\n\nGDP_analysis |&gt;\n  ggplot(aes(x = GDP_Group, y = Account_15plus)) +\n  geom_boxplot()\n\n\n\n{#fig-alt:“Boxplotcomparingfinancialaccountownershiprates(age15+)betweenhigh-GDPandlow-GDPcountries.Theplotshowsthathigh-GDPcountriestendtohavehighermedianaccountownership,withlessvariationcomparedtolow-GDPcountries.” width=672}\n\n\n\n\nResearch question:\nDoes greater access to financial institutions correlate with higher national wealth, as measured by GDP per Capita?\nNull hypothesis:\nThere is no difference in the degree of access to financial institutions between countries with higher and lower GDP per Capita.\nAlternate Hypothesis:\nCountries with a higher GDP per Capita have greater access to financial institutions than those with a lower GDP per Capita.\nPlan:\nTo explore the relationship between a country’s wealth and financial access, I plan to compare the percentage of adults with bank accounts across high- and low-GDP countries. I plan to categorize countries into two groups based on the median GDP per Capita. To determine whether any observed difference in financial access was statistically significant, I plan to conduct a permutation test simulating the null hypothesis of no association. By repeatedly shuffling account access values and calculating the difference between groups, I aim to build a reference distribution to compare against the observed difference.\n\n# Define a function to generate one permutation sample and calculate differences in means and medians\n\nperm_data &lt;- function(rep, data) {\n  data |&gt;\n    select(GDP_Group, Account_15plus) |&gt;\n\n# Randomly permute account ownership values (simulate the null hypothesis)\n\n    mutate(Account_15plus_perm = sample(Account_15plus, replace = FALSE)) |&gt;\n    \n# Group by GDP group to compute observed and permuted group summaries\n\n    group_by(GDP_Group) |&gt;\n    summarize(\n      obs_ave = mean(Account_15plus, na.rm = TRUE),\n      obs_med = median(Account_15plus, na.rm = TRUE),\n      perm_ave = mean(Account_15plus_perm, na.rm = TRUE),\n      perm_med = median(Account_15plus_perm, na.rm = TRUE),\n      .groups = \"drop\"\n    ) |&gt;\n    \n# Calculate the differences between groups (Low GDP - High GDP)\n\n    summarize(\n      obs_ave_diff = diff(obs_ave),\n      obs_med_diff = diff(obs_med),\n      perm_ave_diff = diff(perm_ave),\n      perm_med_diff = diff(perm_med),\n      rep = rep\n    )\n}\n\nperm_results &lt;- map_df(1:1000, perm_data, data = GDP_analysis)\n\nhead(perm_results)\n\n# A tibble: 6 × 5\n  obs_ave_diff obs_med_diff perm_ave_diff perm_med_diff   rep\n         &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1       -0.459       -0.572       -0.0700       -0.155      1\n2       -0.459       -0.572        0.0663        0.131      2\n3       -0.459       -0.572        0.0517        0.101      3\n4       -0.459       -0.572        0.0349        0.0934     4\n5       -0.459       -0.572       -0.0349       -0.0634     5\n6       -0.459       -0.572        0.0286        0.0289     6\n\n\nMy Analysis:\nIn my analysis, I aimed to investigate whether countries with higher GDP per Capita also have greater access to financial institutions. To do this, I began by importing and cleaning the dataset, converting relevant financial indicators to numeric form. I then split countries into “High” and “Low” GDP groups based on the median GDP per Capita. The main variable of interest is the percentage of adults aged 15+ with a bank account. To test whether the observed difference in account access between high- and low-GDP countries could be due to chance, I implemented a permutation test. This involved randomly shuffling the account access values across countries 1,000 times to simulate the distribution of differences we would expect under the null hypothesis of no relationship. For each iteration, I calculated the observed and permuted differences in both means and medians between the two groups. The results allow us to compare the actual observed difference to what we’d expect under random assignment, helping determine whether the relationship between GDP and financial access is statistically meaningful.\n\n# This chunk plots the  distribution of mean differences in account ownership between GDP groups that were ran in the simulation\n\n\nggplot(perm_results, aes(x = perm_ave_diff)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  geom_vline(aes(xintercept = mean(obs_ave_diff)), color = \"red\") +\n  labs(\n    title = \"Permutation Test: Difference in Means of Account Ownership (15+)\",\n    x = \"Difference in Means (Low GDP - High GDP)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n{#fig-alt:“Histogramshowingthedistributionofpermuteddifferencesinmeansoffinancialaccountownership(age15+)betweenlow-GDPandhigh-GDPcountries.Aredverticallineindicatestheobserveddifferencefromtheactualdata.” width=672}\n\n\n\n\n\n# This chunk plots the  distribution of median differences in account ownership between GDP groups that were ran in the simulation\n\n\nggplot(perm_results, aes(x = perm_med_diff)) +\n  geom_histogram(bins = 30, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(aes(xintercept = mean(obs_med_diff)), color = \"blue\",) +\n  labs(\n    title = \"Permutation Test: Difference in Medians of Account Ownership (15+)\",\n    x = \"Difference in Medians (Low GDP - High GDP)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n{#fig-alt:“Histogramshowingthedistributionofpermuteddifferencesinmediansoffinancialaccountownership(age15+)betweenlow-GDPandhigh-GDPcountries.Ablueverticallinemarkstheobservedmediandifferencefromtherealdata.” width=672}\n\n\n\n\nBoth plots present the results of a permutation test designed to evaluate whether there is a statistically significant difference in account ownership (among individuals aged 15 and older) between low-GDP and high-GDP countries. The x-axis on the first plot shows the possible differences in mean account ownership between the two GDP groups that were generated by randomly shuffling the group labels (i.e., permuting which countries are labeled “low” or “high” GDP). In the second plot, it presents the same thing but with the median. Each bar in the histogram represents the frequency of a particular difference in means/medians arising purely by chance under the null hypothesis that GDP classification does not affect financial account ownership.\nThe purpose of this test is to create a distribution of outcomes we might expect to see if there were no real relationship between GDP level and account access, essentially simulating the behavior of the data under random assignment. The vertical line on the graph marks the observed difference in means from the actual dataset (without permutation). This line serves as a reference point: its position relative to the bulk of the histogram tells us whether the observed difference is extreme or typical compared to what might occur under random chance.\nThe lines lie far out to the left where not even one simulation occurs, This indicates that the observed difference did not occur in the 1000 simulations, meaning it is unlikely to occur by chance. This rejects the null hypothesis and suggests that GDP level may be associated with account ownership. Though, since there may be many other factors at play, we can’t claim any sort of causation.\nCitation:\nDemirgüç-Kunt, A., Klapper, L., Singer, D., & Ansar, S. (2022). The Global Findex Database 2021: Financial Inclusion, Digital Payments, and Resilience in the Age of COVID-19. The World Bank. https://www.worldbank.org/en/publication/globalfindex/Data\nWho collected the data? The World Bank’s Development Research Group.\nWhy? To measure how adults worldwide access and use financial services, including accounts, payments, savings, credit, and financial resilience.\nOriginal source: The Global Findex Database 2021, based on nationally representative surveys conducted in over 140 economies.\nWorldometer. (2024). GDP per Capita. Retrieved from https://www.worldometers.info/gdp/gdp-per-capita/\nWho collected the data? Worldometer, compiling data from sources such as the World Bank’s World Development Indicators.\nWhy? To provide up-to-date GDP per capita figures for countries worldwide, facilitating economic comparisons.\nOriginal source: World Bank’s World Development Indicators, as cited by Worldometer.\nI combind two different data sets that came from these cited sources and complied it all into one data set"
  },
  {
    "objectID": "DataEthics.html",
    "href": "DataEthics.html",
    "title": "DataEthics",
    "section": "",
    "text": "Introduction:\nImagine you get caught committing a petty crime, such as stealing someone’s purse out of their car, and you find yourself in court negotiating your parole and sentence with a judge. During this delegation, you are asked to fill out a test of 137 questions to predict how dangerous you may be in the future and whether you will get parole. Now, imagine you are a person of color. You may find that the algorithm predicted you to be much more dangerous in the future than a white individual who did something similar or worse, and you receive a harsher sentence. Also, imagine you learn that information about your previous offenses and personal history was fed to the algorithm without your consent. The algorithm was designed to determine how to rehabilitate people, not how to sentence them.\nThis situation often happens with the use of a predictive algorithm called COMPAS, which analyzes answers to 137 questions, ranging from criminal history to personal background, such as whether your parents were incarcerated or whether you have a job, to assess your risk level. The tool is designed to forecast the likelihood of a criminal defendant reoffending and is used at several stages of the U.S. criminal justice system, including pretrial release decisions and sentencing. COMPAS generates risk scores by analyzing data collected from interviews and criminal records.\nJulia Angwin and her colleagues at ProPublica conducted an investigation into COMPAS using data they obtained from the Broward County Sheriff’s Office through the Freedom of Information Act. They collected real-world COMPAS risk scores for over 7,000 individuals arrested in Broward County, Florida, and compared them with actual criminal records over the following two years. This data was used to statistically evaluate the accuracy and fairness of COMPAS predictions. Although the algorithm was about 61% accurate overall, slightly better than random guessing, Angwin’s team found that it made systematic errors based on race. The scores often overestimated risk for Black defendants and underestimated it for white defendants.\nAngwin’s analysis raises serious ethical concerns. Black defendants were far more likely to be labeled high-risk even when they did not reoffend, while white defendants with worse records were often labeled low-risk. These scores can and have influenced people’s freedom, yet the individuals affected do not know how the scores are calculated and have limited ability to challenge them. This lack of transparency and accountability raises urgent concerns about fairness and racial bias in automated decision-making systems used by the justice system.\nWhat was the consent structure for recruiting participants? Were the participants aware of the ways their data would be used for research? Was informed consent possible? Can you provide informed consent for applications that are yet foreseen?\nThe core issue here is informed consent, which requires that participants understand how their data will be used and voluntarily agree to those uses. In the case of COMPAS, individuals were not recruited as research participants. They were criminal defendants whose data was collected to determine the proceedings of their court cases. As Angwin’s investigation shows, defendants were likely unaware that their answers to personal questions, such as whether a parent had been to prison, would later be used in both court proceedings and in external journalism and academic research. Issie Lapowsky, in her WIRED article, reinforces this concern by explaining how data originally collected for case processing was later used to evaluate algorithmic fairness and predictive accuracy, often without any informed consent from the individuals involved. This raises serious questions about whether meaningful consent is even possible in a setting like the criminal justice system. Both Angwin and Lapowsky show how difficult it is to secure valid consent for future and unforeseen uses, especially when those uses include third-party audits, journalistic investigations, or machine learning research.\nIs the data being used in unintended ways to the original study?\nThe main issue here is mitigating bias in both our models and ourselves, especially when we apply predictive tools to situations that directly affect people’s freedom. This involves identifying and correcting disparities in how predictive models treat different demographic groups. Angwin’s investigation showed that COMPAS produced racially skewed predictions. Black defendants were far more likely than white defendants to be falsely labeled as high-risk. Although COMPAS does not include race as a direct input, the model incorporates proxy variables, such as education level, employment status, and family history, that are deeply shaped by systemic racial inequalities. Lapowsky expands on this point by describing how Dartmouth researchers compared COMPAS to predictions made by Mechanical Turk workers and found similar racial disparities, even though neither group used race as a variable. This suggests that bias is embedded in the structure of the data itself. The fact that COMPAS was used in sentencing decisions, even though it was originally intended for case management, shows how predictive tools can be used in unintended ways, increasing the risk of harm.\nShould race be used as a variable? Is it a proxy for something else (e.g., amount of melanin in the skin, stress of navigating microaggressions, zip-code, etc.)? What about gender?\nThe core question here is whether including or excluding race makes a model more fair or more biased. According to Angwin, COMPAS does not directly include race as a variable. However, variables like prior convictions, family incarceration, and employment status serve as proxies. These are not neutral features; they are shaped by long-standing inequalities in housing, education, and policing. Lapowsky’s article confirms that even when race was withheld from both humans and algorithms, false positive rates were still higher for Black defendants. This shows that excluding race does not eliminate bias but instead makes it harder to detect and correct. Dartmouth researchers found that just two variables—age and number of prior offenses—were enough to replicate COMPAS’s predictions, but these also reflect racial disparities in policing and prosecution. Gender works in a similar way. While it may appear to be a neutral input, it can reinforce stereotypes and institutional biases if not handled carefully. Both Angwin and Lapowsky argue that removing sensitive attributes like race or gender from predictive models does not ensure fairness and may actually hide inequities. One possibility would be to explicitly include race and use it to weigh certain variables, such as family incarceration and employment status, less heavily for historically marginalized groups. However, this strategy could backfire and introduce other forms of unfairness if not applied carefully.\nHow were the variables collected? Were they accurately recorded? Is there any missing data?\nThe key concern here is data integrity. In Angwin’s investigation, COMPAS relied on both self-reported questionnaires and criminal records. Many of the 137 variables are based on personal opinions or unverifiable information, such as a person’s views on authority or their peers’ behavior. This raises questions about accuracy, especially in institutional settings where individuals may not respond freely or truthfully. Lapowsky also notes that COMPAS collects dozens of data points per defendant, many of which are opaque or not publicly disclosed. The company behind COMPAS has never published the full list of variables or how they are weighted, making it impossible to audit the system. This lack of transparency means researchers and affected individuals cannot check for missing data or inconsistent methods. According to Lapowsky, even when researchers used only seven variables in a simplified model, they achieved similar accuracy to COMPAS. This suggests that much of the additional data may not improve performance and could introduce more bias or error.\nCitations:\nAngwin, Julia, et al. “Machine Bias: There’s Software Used across the Country to Predict Future Criminals. And It’s Biased against Blacks.” ProPublica, 23 May 2016, www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\nLapowsky, Issie. “Crime-Predicting Algorithms May Not Fare Much Better Than Untrained Humans.” WIRED, 17 Jan. 2018, https://www.wired.com/story/crime-predicting-algorithms-may-not-outperform-untrained-humans/."
  },
  {
    "objectID": "NFLsalaries.html",
    "href": "NFLsalaries.html",
    "title": "NFL Salaries by Position",
    "section": "",
    "text": "Introduction:\nTo explore how player compensation varies across different roles in the NFL, I analyzed a dataset containing salary data by position. Initially, the data was in wide format, with each column representing a different player position. To better visualize and compare the salary distributions across these positions, I reshaped the dataset into a long format using a pivot operation. This allowed me to create a single box plot chart displaying the spread, median, and variability of salaries for each position. The resulting visualization reveals clear disparities—most notably, the consistently higher salaries earned by quarterbacks, while positions like special teamer and safeties tend to fall on the lower end of the pay scale. This plot offers an accessible summary of the economic hierarchy within professional football.\nExploratory Analysis:\n\nlibrary(readxl)\nlibrary(dplyr)\n\n# Load the data\nnfl_salary &lt;- read_excel(\"nfl_salary.xlsx\")\n\n# Show the first few rows of the full dataset with all original variables\nhead(nfl_salary, 10)\n\n# A tibble: 10 × 11\n    year Cornerback `Defensive Lineman` Linebacker `Offensive Lineman`\n   &lt;dbl&gt;      &lt;dbl&gt;               &lt;dbl&gt;      &lt;dbl&gt;               &lt;dbl&gt;\n 1  2011   11265916            17818000   16420000            15960000\n 2  2011   11000000            16200000   15623000            12800000\n 3  2011   10000000            12476000   11825000            11767500\n 4  2011   10000000            11904706   10083333            10358200\n 5  2011   10000000            11762782   10020000            10000000\n 6  2011    9244117            11340000    8150000             9859166\n 7  2011    8000000            10000000    7812500             9500000\n 8  2011    7900000             9482500    7700000             9420000\n 9  2011    7400000             8450000    7200000             8880000\n10  2011    7000000             8383266    7100000             8686750\n# ℹ 6 more variables: Quarterback &lt;dbl&gt;, `Running Back` &lt;dbl&gt;, Safety &lt;dbl&gt;,\n#   `Special Teamer` &lt;dbl&gt;, `Tight End` &lt;dbl&gt;, `Wide Receiver` &lt;dbl&gt;\n\n\nVariables:\n\nyear - The year the salary data was recorded\nCorner back - Salary of the top-paid cornerbacks that year (USD)\nDefensive Lineman - Salary of the top-paid defensive linemen (USD)\nLinebacker - Salary of the top-paid linebackers (USD)\nOffensive Lineman - Salary of the top-paid offensive linemen (USD)\nQuarterback - Salary of the top-paid quarterbacks (USD)\nRunning Back - Salary of the top-paid running backs (USD)\nSafety - Salary of the top-paid safeties (USD)\nSpecial Teamer - Salary of the top-paid special teams players (USD)\nTight End - Salary of the top-paid tight ends (USD)\nWide Receiver - Salary of the top-paid wide receivers (USD)\n\n\n# Load necessary libraries for data manipulation and visualization\n\nlibrary(tidyverse)\nlibrary(readxl)\n\n# Read the Excel file containing NFL salary data\n\nfile_path &lt;- \"nfl_salary.xlsx\"\nnfl_salary &lt;- read_excel(file_path)\n\n# Reshape the data from wide to long format\n# Keeps 'year' as is, and stacks the salary data by position into two columns: 'position' and 'salary'\n\nnfl_long &lt;- nfl_salary |&gt;\n  pivot_longer(\n    cols = -year,\n    names_to = \"position\",\n    values_to = \"salary\"\n  )\n\n# Create a boxplot to visualize salary distribution by NFL position\n\nggplot(nfl_long, aes(x = position, y = salary)) +\n  geom_boxplot(fill = \"lightblue\") +\n  theme_minimal() +\n  labs(title = \"NFL Salaries by Position\", x = \"Position\", y = \"Salary\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThis boxplot shows the distribution of NFL player salaries by position. Each box represents the range of salaries for a given position across multiple players, highlighting the median, quartiles, and potential outliers. It allows for easy comparison of pay differences between positions, such as the typically higher salaries of quarterbacks compared to special teamers.\nCitations:\nTidyTuesday source: Mock, T., & TidyTuesday Project. (2018, April 9). NFL salary data. TidyTuesday. Retrieved from https://github.com/rfordatascience/tidytuesday/blob/main/data/2018/2018-04-09/nfl_salary.xlsx\nOriginal data source: Original data from Spotrac. (n.d.). NFL player contracts. Spotrac. Retrieved from https://www.spotrac.com/nfl/rankings/\nAdditional citation context:\n\nCollector: The dataset was compiled and shared by Thomas Mock as part of the weekly TidyTuesday project.\nPurpose: The dataset is intended for data visualization and wrangling practice in the R programming language.\nOriginal source: The salary data was scraped from Spotrac, a site that tracks sports contracts and salaries.\nWhy collected: This dataset was curated to encourage open data analysis, reproducible research, and collaborative learning among the R community."
  },
  {
    "objectID": "SQL.html",
    "href": "SQL.html",
    "title": "SQL",
    "section": "",
    "text": "Introduction:\nIn this project, I investigate racial disparities in police search behavior during traffic stops across six U.S. cities: Nashville, Charlotte, Saint Paul, New Orleans, and Austin, Using data from the Stanford Open Policing Project, I analyze whether Black and White drivers experience different search rates, and how those rates have changed over time. My approach involves querying each city’s data using SQL to summarize annual stop counts, search counts, and calculated search rates by race. I then compare these trends both within and across cities to identify patterns of disparity or improvement over time.\nExploratory analysis:\n\nlibrary(DBI)\nlibrary(RMariaDB)\n\n# Establish a secure connection to the 'traffic' database using environmental credentials\ncon_traffic &lt;- DBI::dbConnect(\n  RMariaDB::MariaDB(),\n  dbname = \"traffic\",\n  host = Sys.getenv(\"TRAFFIC_HOST\"),\n  user = Sys.getenv(\"TRAFFIC_USER\"),\n  password = Sys.getenv(\"TRAFFIC_PWD\")\n)\n\n# List all available tables in the connected database\nDBI::dbListTables(con_traffic)\n\n [1] \"ar_little_rock_2020_04_01\"      \"az_gilbert_2020_04_01\"         \n [3] \"az_mesa_2023_01_26\"             \"az_statewide_2020_04_01\"       \n [5] \"ca_anaheim_2020_04_01\"          \"ca_bakersfield_2020_04_01\"     \n [7] \"ca_long_beach_2020_04_01\"       \"ca_los_angeles_2020_04_01\"     \n [9] \"ca_oakland_2020_04_01\"          \"ca_san_bernardino_2020_04_01\"  \n[11] \"ca_san_diego_2020_04_01\"        \"ca_san_francisco_2020_04_01\"   \n[13] \"ca_san_jose_2020_04_01\"         \"ca_santa_ana_2020_04_01\"       \n[15] \"ca_statewide_2023_01_26\"        \"ca_stockton_2020_04_01\"        \n[17] \"co_aurora_2023_01_26\"           \"co_denver_2020_04_01\"          \n[19] \"co_statewide_2020_04_01\"        \"ct_hartford_2020_04_01\"        \n[21] \"ct_statewide_2020_04_01\"        \"fl_saint_petersburg_2020_04_01\"\n[23] \"fl_statewide_2020_04_01\"        \"fl_tampa_2020_04_01\"           \n[25] \"ga_statewide_2020_04_01\"        \"ia_statewide_2020_04_01\"       \n[27] \"id_idaho_falls_2020_04_01\"      \"il_chicago_2023_01_26\"         \n[29] \"il_statewide_2020_04_01\"        \"in_fort_wayne_2020_04_01\"      \n[31] \"ks_wichita_2023_01_26\"          \"ky_louisville_2023_01_26\"      \n[33] \"ky_owensboro_2020_04_01\"        \"la_new_orleans_2020_04_01\"     \n[35] \"ma_statewide_2020_04_01\"        \"md_baltimore_2020_04_01\"       \n[37] \"md_statewide_2020_04_01\"        \"mi_statewide_2020_04_01\"       \n[39] \"mn_saint_paul_2020_04_01\"       \"mo_statewide_2020_04_01\"       \n[41] \"ms_statewide_2020_04_01\"        \"mt_statewide_2023_01_26\"       \n[43] \"nc_charlotte_2020_04_01\"        \"nc_durham_2020_04_01\"          \n[45] \"nc_fayetteville_2020_04_01\"     \"nc_greensboro_2020_04_01\"      \n[47] \"nc_raleigh_2020_04_01\"          \"nc_statewide_2020_04_01\"       \n[49] \"nc_winston_salem_2020_04_01\"    \"nd_grand_forks_2020_04_01\"     \n[51] \"nd_statewide_2020_04_01\"        \"ne_statewide_2020_04_01\"       \n[53] \"nh_statewide_2020_04_01\"        \"nj_camden_2020_04_01\"          \n[55] \"nj_statewide_2020_04_01\"        \"nv_henderson_2020_04_01\"       \n[57] \"nv_statewide_2020_04_01\"        \"ny_albany_2020_04_01\"          \n[59] \"ny_statewide_2020_04_01\"        \"oh_cincinnati_2020_04_01\"      \n[61] \"oh_columbus_2020_04_01\"         \"oh_statewide_2020_04_01\"       \n[63] \"ok_oklahoma_city_2023_01_26\"    \"ok_tulsa_2020_04_01\"           \n[65] \"or_statewide_2020_04_01\"        \"pa_philadelphia_2020_04_01\"    \n[67] \"ri_statewide_2020_04_01\"        \"sc_statewide_2020_04_01\"       \n[69] \"sd_statewide_2020_04_01\"        \"tn_nashville_2020_04_01\"       \n[71] \"tn_statewide_2020_04_01\"        \"tx_arlington_2020_04_01\"       \n[73] \"tx_austin_2020_04_01\"           \"tx_garland_2020_04_01\"         \n[75] \"tx_houston_2023_01_26\"          \"tx_lubbock_2020_04_01\"         \n[77] \"tx_plano_2020_04_01\"            \"tx_san_antonio_2023_01_26\"     \n[79] \"tx_statewide_2020_04_01\"        \"va_statewide_2020_04_01\"       \n[81] \"vt_burlington_2023_01_26\"       \"vt_statewide_2020_04_01\"       \n[83] \"wa_seattle_2020_04_01\"          \"wa_statewide_2020_04_01\"       \n[85] \"wa_tacoma_2020_04_01\"           \"wi_madison_2023_01_26\"         \n[87] \"wi_statewide_2020_04_01\"        \"wy_statewide_2020_04_01\"       \n\n\n\n# Query Nashville traffic stop data to calculate search rates for Black and White drivers by year\n\nSELECT \n  'Nashville' AS city,\n  subject_race AS race,\n  YEAR(date) AS year,\n  COUNT(*) AS total_stops,\n  SUM(search_conducted) AS searches,\n  ROUND(SUM(search_conducted) * 1.0 / COUNT(*), 3) AS search_rate\nFROM tn_nashville_2020_04_01\nWHERE \n  subject_race IN ('black', 'white') AND\n  date IS NOT NULL AND\n  search_conducted IS NOT NULL\nGROUP BY subject_race, YEAR(date)\nORDER BY subject_race, YEAR(date);\n\n\nDisplaying records 1 - 10\n\n\ncity\nrace\nyear\ntotal_stops\nsearches\nsearch_rate\n\n\n\n\nNashville\nblack\n2010\n115023\n7451\n0.065\n\n\nNashville\nblack\n2011\n153025\n8586\n0.056\n\n\nNashville\nblack\n2012\n173393\n9184\n0.053\n\n\nNashville\nblack\n2013\n160925\n9293\n0.058\n\n\nNashville\nblack\n2014\n155570\n9106\n0.059\n\n\nNashville\nblack\n2015\n129698\n7530\n0.058\n\n\nNashville\nblack\n2016\n109146\n6517\n0.060\n\n\nNashville\nblack\n2017\n88745\n5110\n0.058\n\n\nNashville\nblack\n2018\n75310\n4886\n0.065\n\n\nNashville\nblack\n2019\n5016\n322\n0.064\n\n\n\n\n\nIn Nashville, I examined racial disparities in police searches over time. The data show the number of total stops, searches, and the resulting search rate for Black and White drivers from each year. This allows us to track whether search rates differ by race and whether those disparities have changed over time.\n\n\n# Query Charlotte traffic stop data to calculate search rates for Black and White drivers by year\n\nSELECT \n  'Charlotte' AS city,\n  subject_race AS race,\n  YEAR(date) AS year,\n  COUNT(*) AS total_stops,\n  SUM(search_conducted) AS searches,\n  ROUND(SUM(search_conducted) * 1.0 / COUNT(*), 3) AS search_rate\nFROM tn_nashville_2020_04_01\nWHERE \n  subject_race IN ('black', 'white') AND\n  date IS NOT NULL AND\n  search_conducted IS NOT NULL\nGROUP BY subject_race, YEAR(date)\nORDER BY subject_race, YEAR(date);\n\n\nDisplaying records 1 - 10\n\n\ncity\nrace\nyear\ntotal_stops\nsearches\nsearch_rate\n\n\n\n\nCharlotte\nblack\n2010\n115023\n7451\n0.065\n\n\nCharlotte\nblack\n2011\n153025\n8586\n0.056\n\n\nCharlotte\nblack\n2012\n173393\n9184\n0.053\n\n\nCharlotte\nblack\n2013\n160925\n9293\n0.058\n\n\nCharlotte\nblack\n2014\n155570\n9106\n0.059\n\n\nCharlotte\nblack\n2015\n129698\n7530\n0.058\n\n\nCharlotte\nblack\n2016\n109146\n6517\n0.060\n\n\nCharlotte\nblack\n2017\n88745\n5110\n0.058\n\n\nCharlotte\nblack\n2018\n75310\n4886\n0.065\n\n\nCharlotte\nblack\n2019\n5016\n322\n0.064\n\n\n\n\n\nThis query analyzes police search behavior in Charlotte. By comparing the yearly search rates for Black and White drivers, we can identify whether racial disparities exist and whether they have narrowed or widened in recent years. The summary table gives a year-by-year breakdown of search activity.\n\n\n# Query Saint Paul traffic stop data to calculate search rates for Black and White drivers by year\n\nSELECT \n  'Saint Paul' AS city,\n  subject_race AS race,\n  YEAR(date) AS year,\n  COUNT(*) AS total_stops,\n  SUM(search_conducted) AS searches,\n  ROUND(SUM(search_conducted) * 1.0 / COUNT(*), 3) AS search_rate\nFROM tn_nashville_2020_04_01\nWHERE \n  subject_race IN ('black', 'white') AND\n  date IS NOT NULL AND\n  search_conducted IS NOT NULL\nGROUP BY subject_race, YEAR(date)\nORDER BY subject_race, YEAR(date);\n\n\nDisplaying records 1 - 10\n\n\ncity\nrace\nyear\ntotal_stops\nsearches\nsearch_rate\n\n\n\n\nSaint Paul\nblack\n2010\n115023\n7451\n0.065\n\n\nSaint Paul\nblack\n2011\n153025\n8586\n0.056\n\n\nSaint Paul\nblack\n2012\n173393\n9184\n0.053\n\n\nSaint Paul\nblack\n2013\n160925\n9293\n0.058\n\n\nSaint Paul\nblack\n2014\n155570\n9106\n0.059\n\n\nSaint Paul\nblack\n2015\n129698\n7530\n0.058\n\n\nSaint Paul\nblack\n2016\n109146\n6517\n0.060\n\n\nSaint Paul\nblack\n2017\n88745\n5110\n0.058\n\n\nSaint Paul\nblack\n2018\n75310\n4886\n0.065\n\n\nSaint Paul\nblack\n2019\n5016\n322\n0.064\n\n\n\n\n\nThe Saint Paul data highlights racial disparities in search rates between Black and White drivers. Each row summarizes stop and search activity for a particular year, helping us assess whether the city’s policing practices have evolved or remained consistent over time.\n\n\n# Query New Orleans traffic stop data to calculate search rates for Black and White drivers by year\n\nSELECT \n  'New Orleans' AS city,\n  subject_race AS race,\n  YEAR(date) AS year,\n  COUNT(*) AS total_stops,\n  SUM(search_conducted) AS searches,\n  ROUND(SUM(search_conducted) * 1.0 / COUNT(*), 3) AS search_rate\nFROM tn_nashville_2020_04_01\nWHERE \n  subject_race IN ('black', 'white') AND\n  date IS NOT NULL AND\n  search_conducted IS NOT NULL\nGROUP BY subject_race, YEAR(date)\nORDER BY subject_race, YEAR(date);\n\n\nDisplaying records 1 - 10\n\n\ncity\nrace\nyear\ntotal_stops\nsearches\nsearch_rate\n\n\n\n\nNew Orleans\nblack\n2010\n115023\n7451\n0.065\n\n\nNew Orleans\nblack\n2011\n153025\n8586\n0.056\n\n\nNew Orleans\nblack\n2012\n173393\n9184\n0.053\n\n\nNew Orleans\nblack\n2013\n160925\n9293\n0.058\n\n\nNew Orleans\nblack\n2014\n155570\n9106\n0.059\n\n\nNew Orleans\nblack\n2015\n129698\n7530\n0.058\n\n\nNew Orleans\nblack\n2016\n109146\n6517\n0.060\n\n\nNew Orleans\nblack\n2017\n88745\n5110\n0.058\n\n\nNew Orleans\nblack\n2018\n75310\n4886\n0.065\n\n\nNew Orleans\nblack\n2019\n5016\n322\n0.064\n\n\n\n\n\nIn New Orleans, I explore annual search rates for Black and White drivers. This table helps reveal whether racial disparities in search behavior exist and if they are persistent across years. The presence of any consistent differences can point to systemic patterns in local policing.\n\n\n# Query Austin traffic stop data to calculate search rates for Black and White drivers by year\n\nSELECT \n  'Austin' AS city,\n  subject_race AS race,\n  YEAR(date) AS year,\n  COUNT(*) AS total_stops,\n  SUM(search_conducted) AS searches,\n  ROUND(SUM(search_conducted) * 1.0 / COUNT(*), 3) AS search_rate\nFROM tn_nashville_2020_04_01\nWHERE \n  subject_race IN ('black', 'white') AND\n  date IS NOT NULL AND\n  search_conducted IS NOT NULL\nGROUP BY subject_race, YEAR(date)\nORDER BY subject_race, YEAR(date);\n\n\nDisplaying records 1 - 10\n\n\ncity\nrace\nyear\ntotal_stops\nsearches\nsearch_rate\n\n\n\n\nAustin\nblack\n2010\n115023\n7451\n0.065\n\n\nAustin\nblack\n2011\n153025\n8586\n0.056\n\n\nAustin\nblack\n2012\n173393\n9184\n0.053\n\n\nAustin\nblack\n2013\n160925\n9293\n0.058\n\n\nAustin\nblack\n2014\n155570\n9106\n0.059\n\n\nAustin\nblack\n2015\n129698\n7530\n0.058\n\n\nAustin\nblack\n2016\n109146\n6517\n0.060\n\n\nAustin\nblack\n2017\n88745\n5110\n0.058\n\n\nAustin\nblack\n2018\n75310\n4886\n0.065\n\n\nAustin\nblack\n2019\n5016\n322\n0.064\n\n\n\n\n\nThe Austin dataset provides insight into how stop and search practices differ by race over time. The query outputs a breakdown of total stops, number of searches, and calculated search rates, allowing a clear comparison of treatment between Black and White drivers on a yearly basis.\n\n\n#This query extracts and combines stop and search counts by race and year for Black and White drivers in Nashville, Charlotte, Saint Paul, New Orleans, and Austin.\n\nSELECT 'Nashville' AS city, subject_race AS race, YEAR(date) AS year,\n       COUNT(*) AS total_stops,\n       SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches\nFROM tn_nashville_2020_04_01\nWHERE subject_race IN ('black', 'white')\nGROUP BY subject_race, YEAR(date)\n\nUNION ALL\n\nSELECT 'Charlotte' AS city, subject_race AS race, YEAR(date) AS year,\n       COUNT(*) AS total_stops,\n       SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches\nFROM nc_charlotte_2020_04_01\nWHERE subject_race IN ('black', 'white')\nGROUP BY subject_race, YEAR(date)\n\nUNION ALL\n\nSELECT 'Saint Paul' AS city, subject_race AS race, YEAR(date) AS year,\n       COUNT(*) AS total_stops,\n       SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches\nFROM mn_saint_paul_2020_04_01\nWHERE subject_race IN ('black', 'white')\nGROUP BY subject_race, YEAR(date)\n\nUNION ALL\n\nSELECT 'New Orleans' AS city, subject_race AS race, YEAR(date) AS year,\n       COUNT(*) AS total_stops,\n       SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches\nFROM la_new_orleans_2020_04_01\nWHERE subject_race IN ('black', 'white')\nGROUP BY subject_race, YEAR(date)\n\nUNION ALL\n\nSELECT 'Austin' AS city, subject_race AS race, YEAR(date) AS year,\n       COUNT(*) AS total_stops,\n       SUM(CASE WHEN search_conducted = TRUE THEN 1 ELSE 0 END) AS searches\nFROM tx_austin_2020_04_01\nWHERE subject_race IN ('black', 'white')\nGROUP BY subject_race, YEAR(date);\n\n\n# Create a line plot showing the proportion of stops that resulted in a search by race and city across years, faceted by city\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndf |&gt;\n  mutate(year = as.numeric(year)) |&gt;\n  ggplot(aes(x = year, y = searches / total_stops, color = race)) +\n  geom_line(size = 1.2) +\n  facet_wrap(~ city) +\n  labs(title = \"Search Rate Over Time by Race and City\",\n       x = \"Year\", y = \"Search Rate\",\n       color = \"Driver Race\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis plot displays search rates over time for Black and White drivers in each of the six cities included in the analysis seperated into 6 graphs per city. Each line represents the percentage of stops that resulted in a search for each racial group, by year. Across all cities, Black drivers consistently experienced higher search rates than White drivers. The gap between the two groups is visible in most cities and remains relatively stable over time, suggesting a persistent racial disparity in search practices.\n\n# This code creates a bar chart showing how many traffic stops occurred for Black and White drivers in each of five cities.\n\ndf |&gt;\n  group_by(city, race) |&gt;\n  summarise(total_stops = sum(total_stops)) |&gt;\n  ggplot(aes(x = city, y = total_stops, fill = race)) +\n  geom_col(position = \"dodge\") +\n  labs(title = \"Total Stops by Race and City\",\n       x = \"City\", y = \"Total Stops\", fill = \"Race\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis bar chart compares the total number of stops for Black and White drivers in each city over the full time period covered by the data. It shows this by having total stops on the y-axis and cities on the x-axis. We can see two bars for each city to show how many times black people were stopped and how many times white people were stopped. While some cities show more stops for White drivers and others for Black drivers, this variation likely reflects differences in each city’s racial demographics rather than disparities in policing alone. It could also be attributed to having some incomplete or less data in some years This plot provides important context for interpreting the search rate data by showing the baseline number of stops per group.\nConclusion: Through querying traffic stop data across six U.S. cities using SQL, I analyzed how search rates compare between Black and White individuals over multiple years. By combining city-level results into a unified dataset, I was able to observe trends within and across locations, comparing both the rate and total number of searches by race. The analysis revealed that Black drivers consistently experienced higher search rates than White drivers in every city studied. While the magnitude of disparity varied by city and year, the pattern was both persistent and systemic. Interestingly, when comparing the total number of searches, the dominant racial group varied by city—likely reflecting differences in local demographic composition rather than search behavior alone.\nCitation: Pierson, Emma, Camelia Simoiu, Jan Overgoor, Sam Corbett-Davies, Daniel Jenson, Amy Shoemaker, Vignesh Ramachandran, et al. 2020. “A Large-Scale Analysis of Racial Disparities in Police Stops Across the United States.” Nature Human Behaviour, 1–10.\nWho collected the data? The data was collected and analyzed by a multidisciplinary research team led by Emma Pierson, with co-authors from Stanford University, including members of the Stanford Computational Policy Lab and other researchers from academia and civic technology.\nWhy? The data was gathered to conduct one of the largest empirical investigations into racial disparities in police traffic stops in the United States. The study sought to measure disparities in stop rates, search decisions, and outcomes, and to test whether these disparities could be explained by differences in behavior versus systemic bias.\nOriginal source: The underlying stop data was obtained from publicly available datasets released by state and local law enforcement agencies across the U.S., covering over 100 million traffic stops. The Stanford Open Policing Project (https://openpolicing.stanford.edu) played a central role in assembling and standardizing this data for research use."
  },
  {
    "objectID": "FastFood.html",
    "href": "FastFood.html",
    "title": "FastFood",
    "section": "",
    "text": "Introduction:\nTo understand how caloric content varies across different fast food restaurants, I analyzed a dataset containing menu item information from multiple chains. After importing the data, I focused on the calories variable and used ggplot2 to create box-plots of calorie counts for each restaurant. By using facet_wrap, I generated separate plots for each chain, allowing for side-by-side comparison of the distribution of calories per item. This visualization helps identify which restaurants tend to offer higher-calorie foods and which ones have more balanced or lower-calorie options.\nExploratory Analysis:\n\nlibrary(readxl)\nlibrary(dplyr)\n\n# Load the data\nFast_Food &lt;- read_excel(\"Fast Food.xlsx\")\n\n# Show the first few rows of the full dataset with all original variables\nhead(Fast_Food, 10)\n\n# A tibble: 10 × 18\n    ...1 restaurant item            calories cal_fat total_fat sat_fat trans_fat\n   &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;\n 1     1 Mcdonalds  Artisan Grille…      380      60         7       2       0  \n 2     2 Mcdonalds  Single Bacon S…      840     410        45      17       1.5\n 3     3 Mcdonalds  Double Bacon S…     1130     600        67      27       3  \n 4     4 Mcdonalds  Grilled Bacon …      750     280        31      10       0.5\n 5     5 Mcdonalds  Crispy Bacon S…      920     410        45      12       0.5\n 6     6 Mcdonalds  Big Mac              540     250        28      10       1  \n 7     7 Mcdonalds  Cheeseburger         300     100        12       5       0.5\n 8     8 Mcdonalds  Classic Chicke…      510     210        24       4       0  \n 9     9 Mcdonalds  Double Cheeseb…      430     190        21      11       1  \n10    10 Mcdonalds  Double Quarter…      770     400        45      21       2.5\n# ℹ 10 more variables: cholesterol &lt;dbl&gt;, sodium &lt;dbl&gt;, total_carb &lt;dbl&gt;,\n#   fiber &lt;chr&gt;, sugar &lt;dbl&gt;, protein &lt;chr&gt;, vit_a &lt;chr&gt;, vit_c &lt;chr&gt;,\n#   calcium &lt;chr&gt;, salad &lt;chr&gt;\n\n\nVariables:\n\nrestaurant: Name of the fast food chain (e.g., McDonald’s, Burger King).\nitem: Specific menu item.\ncalories: Total calories in the item.\ncal_fat: Calories from fat.\ntotal_fat: Total fat in grams.\nsaturated_fat: Saturated fat in grams.\ntrans_fat: Trans fat in grams.\ncholesterol: Cholesterol in milligrams.\nsodium: Sodium in milligrams.\ntotal_carb: Total carbohydrates in grams.\nfiber: Dietary fiber in grams.\nsugar: Sugars in grams.\nprotein: Protein in grams.\nvit_a: Vitamin A percentage of daily value.\nvit_c: Vitamin C percentage of daily value.\ncalcium: Calcium percentage of daily value.\nsalad: Indicator if the item is a salad (TRUE/FALSE).\n\n\n# Load necessary libraries for data manipulation and visualization\nlibrary(tidyverse)\nlibrary(readxl)\n\n# Read in the Excel file containing the fast food nutrition data\nfile_path &lt;- \"Fast Food.xlsx\"\nFast_Food &lt;- read_excel(file_path)\n\n# Create a boxplot to visualize the distribution of calories for each restaurant\nggplot(Fast_Food, aes(x = calories)) +\n  geom_boxplot(color = \"darkred\")+\n  facet_wrap(~restaurant)+\n  labs(title = \"Calorie distribution of each restaurant's menu\")\n\n\n\n\n\n\n\n\nThis set of boxplots displays the distribution of calorie counts for menu items at various fast food restaurants. Each panel represents a different chain, showing the spread of calories offered on their menus. The boxes illustrate the interquartile range (middle 50% of items), the horizontal line inside each box shows the median calorie count, and dots (if any) highlight outlier items with unusually high or low calories. This visual makes it easy to compare how calorie-dense different menus are across fast food brands.\nExtra Credit:\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(plotly)\n\n# Read the data\nFast_Food &lt;- read_excel(\"Fast Food.xlsx\")\n\n# Create corrected boxplot\np &lt;- ggplot(Fast_Food, aes(x = restaurant, y = calories)) +\n  geom_boxplot(color = \"darkred\") +\n  labs(title = \"Calorie Distribution by Restaurant\",\n       x = \"Restaurant\", y = \"Calories\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# Convert to interactive plot\ninteractive_plot &lt;- ggplotly(p)\ninteractive_plot\n\n\n\n\n\nFor my extra credit, I improved my original fast food calorie graph by turning it from a regular static chart into an interactive one using Plotly. My original graph used boxplots to show how calories are spread out across different restaurants, which made it easy to spot things like medians and outliers. But the static version had some downsides—it didn’t let viewers see exact values or easily compare restaurants, especially when the data overlapped. By switching to Plotly, I made the chart interactive so users can now hover over each box to see specific calorie numbers, zoom in on certain restaurants, and explore the data in more detail. This makes the chart easier to use and more interesting to look at. It also helps people better understand the differences in calorie content between restaurants by letting them explore the data on their own.\nCitations\nTidyTuesday source: Hughes, Ellis ., & the R for Data Science Online Learning Community. (2018, September 4). Fast Food Calories – TidyTuesday Dataset. Retrieved from https://github.com/rfordatascience/tidytuesday/tree/main/data/2018/2018-09-04\nOriginal data source: Fast Food Nutrition. (2025, May 6). McDonald’s Nutrition Facts & Calories. Retrieved from https://fastfoodnutrition.org/mcdonalds\nAdditional citation context:\n\nWho collected the data? The data was compiled by Fast Food Nutrition, an independent website that aggregates nutritional information from various fast-food chains.\nWhy it was collected? To provide consumers with accessible and comprehensive nutritional information for menu items at fast-food restaurants, aiding in informed dietary choices.\nOriginal source of the information: The nutritional data originates from all the restaurants official nutritional disclosures and publicly available information."
  },
  {
    "objectID": "Final Presentation.html#introduction-methodology",
    "href": "Final Presentation.html#introduction-methodology",
    "title": "Final Presentation",
    "section": "Introduction & Methodology",
    "text": "Introduction & Methodology\nResearch Question: Does greater access to financial institutions correlate with higher national wealth, as measured by GDP per Capita?\nData Overview:\n\n120 countries\nVariables sourced from World Bank/Wolrdometer\nCountries grouped by median GDP per Capita:\n\nHigh GDP group: Above median\nLow GDP group: Below median\n\n\nMain Tool:\n\nPermutation Test\nSimulates the null hypothesis: no relationship between GDP and account access\n1,000 iterations with random shuffling"
  },
  {
    "objectID": "Final Presentation.html#data-preperation",
    "href": "Final Presentation.html#data-preperation",
    "title": "Final Presentation",
    "section": "Data Preperation",
    "text": "Data Preperation\n\nlibrary(tidyverse)\nlibrary(readxl)\n\nGDP_analysis &lt;- read_excel(\"GDP_analysis.xlsx\", sheet = \"Data\", skip = 1)\ncolnames(GDP_analysis) &lt;- c(\n  \"Country\", \n  \"GDP_Per_Capita\", \n  \"Account_15plus\", \n  \"Saved_15plus\", \n  \"Borrowed_Formal_15plus\", \n  \"Account_Female\", \n  \"Account_Male\", \n  \"Owns_Credit_Card\")\n\nDP_analysis &lt;- GDP_analysis |&gt; \n  mutate(across(GDP_Per_Capita:Owns_Credit_Card, as.numeric))\n  \nmedian_gdp &lt;- median(GDP_analysis$GDP_Per_Capita, na.rm = TRUE)\n\nGDP_analysis &lt;- GDP_analysis |&gt;  \n  mutate(GDP_Group = ifelse(GDP_Per_Capita &gt;= median_gdp, \"High\", \"Low\"))"
  },
  {
    "objectID": "Final Presentation.html#boxplot-visualization",
    "href": "Final Presentation.html#boxplot-visualization",
    "title": "Final Presentation",
    "section": "Boxplot Visualization",
    "text": "Boxplot Visualization\n\nGDP_analysis |&gt;\n  ggplot(aes( x = GDP_Group, y = Account_15plus )) +\n  geom_boxplot()"
  },
  {
    "objectID": "Final Presentation.html#permutation-test",
    "href": "Final Presentation.html#permutation-test",
    "title": "Final Presentation",
    "section": "Permutation Test",
    "text": "Permutation Test\nNull hypothesis:\nThere is no difference in the degree of access to financial institutions between countries with higher and lower GDP per Capita.\nAlternate Hypothesis:\nCountries with a higher GDP per Capita have greater access to financial institutions than those with a lower GDP per Capita.\n\nperm_data &lt;- function(rep, data) {\n  data |&gt;\n    select(GDP_Group, Account_15plus) |&gt;\n    mutate(Account_15plus_perm = sample(Account_15plus, replace = FALSE)) %&gt;%\n    group_by(GDP_Group) |&gt;\n    summarize(\n      obs_ave = mean(Account_15plus, na.rm = TRUE),\n      obs_med = median(Account_15plus, na.rm = TRUE),\n      perm_ave = mean(Account_15plus_perm, na.rm = TRUE),\n      perm_med = median(Account_15plus_perm, na.rm = TRUE),\n      .groups = \"drop\"\n    ) |&gt;\n    summarize(\n      obs_ave_diff = diff(obs_ave),\n      obs_med_diff = diff(obs_med),\n      perm_ave_diff = diff(perm_ave),\n      perm_med_diff = diff(perm_med),\n      rep = rep\n    )\n}\n\nperm_results &lt;- map_df(1:1000, perm_data, data = GDP_analysis)\n\nhead(perm_results)\n\n# A tibble: 6 × 5\n  obs_ave_diff obs_med_diff perm_ave_diff perm_med_diff   rep\n         &lt;dbl&gt;        &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt; &lt;int&gt;\n1       -0.459       -0.572       0.0612         0.180      1\n2       -0.459       -0.572       0.0149        -0.0564     2\n3       -0.459       -0.572       0.00781       -0.0220     3\n4       -0.459       -0.572       0.00815       -0.0289     4\n5       -0.459       -0.572       0.00361       -0.0355     5\n6       -0.459       -0.572      -0.00140       -0.0220     6"
  },
  {
    "objectID": "Final Presentation.html#permutation-test-results",
    "href": "Final Presentation.html#permutation-test-results",
    "title": "Final Presentation",
    "section": "Permutation test results",
    "text": "Permutation test results\n\nggplot(perm_results, aes(x = perm_ave_diff)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  geom_vline(aes(xintercept = mean(obs_ave_diff)), color = \"red\") +\n  labs(\n    title = \"Permutation Test: Difference in Means of Account Ownership (15+)\",\n    x = \"Difference in Means (Low GDP - High GDP)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(perm_results, aes(x = perm_med_diff)) +\n  geom_histogram(bins = 30, fill = \"lightgreen\", color = \"black\") +\n  geom_vline(aes(xintercept = mean(obs_med_diff)), color = \"blue\",) +\n  labs(\n    title = \"Permutation Test: Difference in Medians of Account Ownership (15+)\",\n    x = \"Difference in Medians (Low GDP - High GDP)\",\n    y = \"Count\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nathan Dhanani",
    "section": "",
    "text": "Hello! My name is Nathan Dhanani and I am an Economic/Finance student at Claremont McKenna College. I am hoping to be an Economic Consultant and am currently interning at Analysis Group. I love playing soccer, lifting weights, pickle ball and Spikeball. Feel free to browse my website to learn more."
  },
  {
    "objectID": "Stinganalysis.html",
    "href": "Stinganalysis.html",
    "title": "StringAnalysis",
    "section": "",
    "text": "Introduction:\nIn today’s media landscape, the New York Times remains one of the most influential news outlets, shaping public discourse on politics and international affairs. To better understand how political topics are covered in NYT headlines, this analysis explores a dataset of article titles, focusing on mentions of key political terms and global locations. By identifying headlines that reference terms like “election,” “president,” or “congress,” and extracting country or region names, we can begin to map out how political attention is distributed across the globe and how it has evolved throughout time. This exploration provides insight into the geographic focus of political reporting, how frequently certain regions appear in headlines, and how this coverage has changed over time. Through a combination of text filtering, and location extraction the following analysis aims to uncover patterns in political narrative emphasis and international visibility in the New York Times.\nExploratory Analysis:\n\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(RTextTools)\n\n# Show the first few rows of the full dataset with all original variables\ndata(NYTimes)\nhead(NYTimes, 10)\n\n   Article_ID      Date\n1       41246  1-Jan-96\n2       41257  2-Jan-96\n3       41268  3-Jan-96\n4       41279  4-Jan-96\n5       41290  5-Jan-96\n6       41302  7-Jan-96\n7       41314  8-Jan-96\n8       41333 10-Jan-96\n9       41344 11-Jan-96\n10      41355 12-Jan-96\n                                                                                            Title\n1                                   Nation's Smaller Jails Struggle To Cope With Surge in Inmates\n2                                                 FEDERAL IMPASSE SADDLING STATES WITH INDECISION\n3                             Long, Costly Prelude Does Little To Alter Plot of Presidential Race\n4                                    Top Leader of the Bosnian Serbs Now Under Attack From Within\n5         BATTLE OVER THE BUDGET: THE OVERVIEW; LEADERS IN HOUSE DROP G.O.P. PLAN ON U.S. WORKERS\n6                                                 South African Democracy Stumbles on Old Rivalry\n7                                                        Among Economists, Little Fear on Deficit\n8          BATTLE OVER THE BUDGET: THE OVERVIEW; TALKS ON BUDGET ARE PUT ON HOLD AMID UNCERTAINTY\n9                                                             High Court Is Cool To Census Change\n10 TURMOIL AT BARNEYS: THE DIFFICULTIES; Barneys Is Seeking Bankruptcy, Citing Fight With Partner\n                                                                                      Subject\n1                                                   Jails overwhelmed with hardened criminals\n2                                                     Federal budget impasse affect on states\n3                                                  Contenders for 1996 Presedential elections\n4                                                  Bosnian Serb leader criticized from within\n5  Battle over budget: Republican leaders abandon strategy of using closed Government offices\n6                                                          political violence in south africa\n7                                                          economists not afraid of a deficit\n8                                                                                budget fight\n9                                                                              census changes\n10                                                                   barneys seeks bankruptcy\n   Topic.Code\n1          12\n2          20\n3          20\n4          19\n5           1\n6          19\n7           1\n8           1\n9          20\n10         15\n\n\nVariables:\n\nArticle_ID - A unique numerical identifier for each article in the dataset\nDate - The publication date of the article (usually in day-month-year format)\nTitle - The article headline as it appeared in The New York Times Subject A brief summary or annotation describing the main idea of the article\nTopic.Code - A numeric code representing the article’s assigned policy topic or issue domain\n\n\n# Load the NYTimes dataset and convert it to a tibble for easier handling\n\ndata(NYTimes)\nas_tibble(NYTimes)\n\n# A tibble: 3,104 × 5\n   Article_ID Date      Title                                 Subject Topic.Code\n        &lt;int&gt; &lt;fct&gt;     &lt;fct&gt;                                 &lt;fct&gt;        &lt;int&gt;\n 1      41246 1-Jan-96  Nation's Smaller Jails Struggle To C… Jails …         12\n 2      41257 2-Jan-96  FEDERAL IMPASSE SADDLING STATES WITH… Federa…         20\n 3      41268 3-Jan-96  Long, Costly Prelude Does Little To … Conten…         20\n 4      41279 4-Jan-96  Top Leader of the Bosnian Serbs Now … Bosnia…         19\n 5      41290 5-Jan-96  BATTLE OVER THE BUDGET: THE OVERVIEW… Battle…          1\n 6      41302 7-Jan-96  South African Democracy Stumbles on … politi…         19\n 7      41314 8-Jan-96  Among Economists, Little Fear on Def… econom…          1\n 8      41333 10-Jan-96 BATTLE OVER THE BUDGET: THE OVERVIEW… budget…          1\n 9      41344 11-Jan-96 High Court Is Cool To Census Change   census…         20\n10      41355 12-Jan-96 TURMOIL AT BARNEYS: THE DIFFICULTIES… barney…         15\n# ℹ 3,094 more rows\n\n\n\n# This chunk filters articles that mention political topics (e.g. \"election\", \"president\", \"congress\") and extracts geographic keywords. It then counts how many political headlines include each location.\n\nNYTimesv2 &lt;- NYTimes |&gt;\n  mutate(politics_mention = str_detect(Title,regex(\"election|vote|senate|president|congress|politics|congress|clinton|trump\", ignore_case = TRUE))) |&gt;\n  mutate(title_word_count = str_count(Title,\"\\\\S+\")) |&gt;\n  mutate(location = str_extract(Title, regex(\"New York|California|Texas|France|Russia|China|Japan|Mexico|Bosnia|Serbia|Germany|UK|USA\", ignore_case = TRUE)))|&gt;\n  mutate(location = str_to_lower(location)) |&gt;\n  filter(politics_mention == TRUE, !is.na(location)) |&gt;\n  group_by(location) |&gt;\n  summarize(article_count = n(), .groups = \"drop\")|&gt;\n    mutate(location = fct_reorder(location, article_count))  \n\n#| fig-alt: “Bar chart showing the number of political headlines in the NYTimes mentioning each of several global locations. Locations are ordered by frequency, with darker fill indicating more mentions.”\n\n# This chunk creates a Bar chart which depicts the most mentioned locations in political articles\nggplot(NYTimesv2, aes(x = location, y = article_count, fill = article_count)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Most Mentioned Locations in Political Articles\",\n       x = \"Location\",\n       y = \"Number of Articles\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis bar chart shows which geographic locations appear most frequently in political articles published by The New York Times. Each bar represents a specific location mentioned in political headlines, based on keywords like “election,” “vote,” “president,” etc. The data has been filtered to include only articles that reference both politics and one of several predefined countries or regions. The color gradient indicates the volume of mentions, making it easier to spot which places dominate the political conversation in NYT headlines.\n\n#In this chunk, we extract the year from each article date and count how many political headlines occurred each year. This helps us track The New York Times political coverage volume over time.\n\nlibrary(lubridate)\nNYTimesv3 &lt;- NYTimes |&gt;\n  mutate(Date = dmy(Date),  \n         Year = year(Date),\n         politics_mention = str_detect(Title, regex(\"election|vote|senate|president|congress|politics|congress|clinton|trump\", ignore_case = TRUE)),\n         title_word_count = str_count(Title,\"\\\\S+\"),\n         location = str_extract(Title, regex(\"New York|California|Texas|France|Russia|China|Japan|Mexico|Bosnia|Serbia|Germany|UK|USA\", ignore_case = TRUE))) |&gt;\n  filter(politics_mention == TRUE, !is.na(location)) |&gt;\n  group_by(Year) |&gt;\n  summarise(article_count = n(), .groups = \"drop\") |&gt;\n  arrange(Year)\n\n#| fig-alt:“Line chart showing the number of political articles in the NYTimes each year that mention major global locations. The line shows increases or dips in coverage volume over time.”\n\n#In this chunk, we create a line chart that counts the amount of political article frequency by year\n\nggplot(NYTimesv3, aes(x = Year, y = article_count)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_point(size = 2, color = \"red\") +\n  labs(title = \"Political Articles Mentioning Key Locations Over Time\",\n       x = \"Year\",\n       y = \"Number of Articles\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis line chart tracks the number of political articles published each year by The New York Times that mention at least one major global location. By focusing only on political headlines containing specific keywords and country names, this plot visualizes how global political focus in NYT coverage has shifted or intensified over time. Spikes or dips in the line may correspond to key events such as presidential elections, international conflicts, or geopolitical crises.\nCitation:\nBoydstun, A. E. (2013). Supplementary Information for: Making the News: Politics, the Media, and Agenda Setting. Retrieved from http://www.amber-boydstun.com/supplementary-information-for-making-the-news.html\nAdditional citation context:\nWho collected the data? The dataset was compiled by Dr. Amber E. Boydstun, a political scientist and professor at the University of California, Davis. She gathered this data as part of her research for the book Making the News: Politics, the Media, and Agenda Setting, which examines patterns in media attention and agenda-setting processes.\nWhy it was collected? The primary aim of collecting this data was to analyze how policy issues gain prominence in media coverage, particularly focusing on the dynamics of news reporting by major outlets like The New York Times. The research sought to understand the factors influencing which issues are highlighted in the news and how this affects public discourse and policy-making.\nOriginal source of the information: The data originates from a systematic content analysis of The New York Times front-page articles spanning from 1996 to 2006. Each article was coded for various attributes, including policy topics, framing, and prominence, to facilitate a comprehensive study of media coverage patterns."
  }
]